#!/usr/bin/env python3
import time
from collections import deque
import numpy as np
import cv2
import math
import sys
import threading
from flask import Flask, Response, jsonify
from gtts import gTTS
import tempfile
import os
import subprocess

def init_audio():
    """Test if audio output works"""
    try:
        subprocess.run(['amixer', 'set', 'Master', '80%'], check=False)
        print("Audio initialized")
        return True
    except:
        print("Audio setup failed")
        return False

audio_available = init_audio()

try:
    from tflite_runtime.interpreter import Interpreter
except Exception:
    from tensorflow.lite.python.interpreter import Interpreter

MODEL_PATH = "/home/theo/4.tflite"
CAMERA_ID = 0
NECK_THRESHOLD = 35
SMOOTHING_FRAMES = 7
BAD_DURATION_TO_ALERT = 2.0
INFER_THREADS = 2

FACE_TOO_CLOSE_RATIO = 0.35
FACE_TOO_FAR_RATIO = 0.08

interpreter = Interpreter(MODEL_PATH, num_threads=INFER_THREADS)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
input_dtype = input_details[0]['dtype']
in_h = input_details[0]['shape'][1]
in_w = input_details[0]['shape'][2]

def neck_angle(hip, shoulder, head, shoulder_ref):
    """Calculate neck angle similar to MediaPipe method"""
    vec1 = hip - shoulder_ref
    vec2 = head - shoulder_ref
    denom = (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    if denom == 0:
        return 0.0
    cosang = np.dot(vec1, vec2) / denom
    cosang = np.clip(cosang, -1.0, 1.0)
    angle = math.degrees(math.acos(cosang))
    return abs(angle - 180.0)

def speak_alert(message):
    """Speak alert in Vietnamese using gTTS"""
    if not audio_available:
        return
    
    def _speak():
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:
                temp_file = fp.name
            
            tts = gTTS(text=message, lang='vi', slow=False)
            tts.save(temp_file)
            
            subprocess.run(['mpg123', '-q', temp_file], check=False)
            
            try:
                os.remove(temp_file)
            except:
                pass
        except Exception as e:
            print(f"TTS error: {e}")
    
    thread = threading.Thread(target=_speak, daemon=True)
    thread.start()

angle_buf = deque(maxlen=SMOOTHING_FRAMES)
last_bad_time = None
alert_playing = False
last_alert_time = 0

cap = cv2.VideoCapture(CAMERA_ID)
if not cap.isOpened():
    print("Cannot open camera")
    sys.exit(1)

cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
cap.set(cv2.CAP_PROP_FPS, 30)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

app = Flask(__name__)
outputFrame = None
lock = threading.Lock()

stats = {
    'posture_status': 'Good',
    'neck_angle': 0,
    'distance_status': 'OK',
    'fps': 0
}

last_display_text = ""
last_distance_status = "OK"
last_fps_text = ""

ALERT_MESSAGES = [
    "Bạn đang cúi đầu quá thấp, hãy ngồi thẳng lại",
    "Tư thế ngồi của bạn không đúng, giữ thẳng lưng nhé",
    "Hãy giữ đầu thẳng với cột sống"
]
alert_index = 0

def detect_posture():
    global outputFrame, last_bad_time, alert_playing, stats
    global last_display_text, last_distance_status, last_fps_text
    global last_alert_time, alert_index
    
    frame_count = 0
    start_time = time.time()
    
    while True:
        ret, frame = cap.read()
        if not ret:
            continue
        
        frame_count += 1
        h, w, _ = frame.shape

        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        img_resized = cv2.resize(img, (in_w, in_h), interpolation=cv2.INTER_NEAREST)
        
        if input_dtype == np.float32:
            inp = img_resized.astype(np.float32)
            inp = (inp - 127.5) / 127.5
            inp = np.expand_dims(inp, axis=0)
        else:
            inp = np.expand_dims(img_resized.astype(input_dtype), axis=0)

        interpreter.set_tensor(input_details[0]['index'], inp)
        interpreter.invoke()
        output_data = interpreter.get_tensor(output_details[0]['index'])

        kpts = output_data[0][0] if output_data.ndim == 4 else output_data[0]

        nose = np.array([kpts[0][1] * w, kpts[0][0] * h])
        s0 = kpts[0][2]
        lear = np.array([kpts[3][1] * w, kpts[3][0] * h])
        s_lear = kpts[3][2]
        rear = np.array([kpts[4][1] * w, kpts[4][0] * h])
        s_rear = kpts[4][2]
        ls = np.array([kpts[5][1] * w, kpts[5][0] * h])
        s1 = kpts[5][2]
        rs = np.array([kpts[6][1] * w, kpts[6][0] * h])
        s2 = kpts[6][2]
        lh = np.array([kpts[11][1] * w, kpts[11][0] * h])
        s3 = kpts[11][2]
        rh = np.array([kpts[12][1] * w, kpts[12][0] * h])
        s4 = kpts[12][2]

        min_conf = 0.25
        key_scores = [s0, s1, s2, s3, s4]
        
        distance_status = "OK"
        if s0 > min_conf:
            if s_lear > min_conf and s_rear > min_conf:
                face_width = np.linalg.norm(lear - rear)
            else:
                face_width = w * 0.15
            
            face_ratio = face_width / w
            
            if face_ratio > FACE_TOO_CLOSE_RATIO:
                distance_status = "TOO CLOSE"
                current_time = time.time()
                if current_time - last_alert_time > 15:
                    speak_alert("Bạn đang ngồi quá gần màn hình, hãy lùi ra xa một chút")
                    last_alert_time = current_time
            elif face_ratio < FACE_TOO_FAR_RATIO:
                distance_status = "Too far"

        if sum(s > min_conf for s in key_scores) < 3:
            posture_status = "Unknown"
            smoothed = 0
            display_text = "No person"
        else:
            mid_shoulder = (ls + rs) * 0.5
            mid_hip = (lh + rh) * 0.5
            
            if s_lear > min_conf and s_rear > min_conf:
                mid_head = (lear + rear) * 0.5
            else:
                mid_head = nose - np.array([0, np.linalg.norm(ls - rs) * 0.4])
            
            angle_val = neck_angle(mid_hip, mid_shoulder, mid_head, mid_shoulder)
            angle_buf.append(angle_val)
            smoothed = float(np.mean(angle_buf))
            
            if frame_count % 2 == 0:
                cv2.line(frame, tuple(mid_hip.astype(int)), tuple(mid_shoulder.astype(int)), (0, 255, 0), 2)
                cv2.line(frame, tuple(mid_shoulder.astype(int)), tuple(mid_head.astype(int)), (0, 255, 0), 2)
            
            if smoothed > NECK_THRESHOLD:
                posture_status = "Bad"
                display_text = f"BAD POSTURE: {smoothed:.1f}deg"
                
                if last_bad_time is None:
                    last_bad_time = time.time()
                elapsed = time.time() - last_bad_time
                if elapsed >= BAD_DURATION_TO_ALERT:
                    current_time = time.time()
                    if current_time - last_alert_time > 10:
                        speak_alert(ALERT_MESSAGES[alert_index])
                        alert_index = (alert_index + 1) % len(ALERT_MESSAGES)
                        last_alert_time = current_time
                        alert_playing = True
            else:
                posture_status = "Good"
                display_text = f"GOOD: {smoothed:.1f}deg"
                last_bad_time = None
                alert_playing = False

        elapsed_time = time.time() - start_time
        fps = frame_count / elapsed_time if elapsed_time > 0 else 0

        if display_text != last_display_text:
            last_display_text = display_text
        if distance_status != last_distance_status:
            last_distance_status = distance_status
        if frame_count % 5 == 0:
            last_fps_text = f"FPS: {fps:.1f}"

        if posture_status == "Bad":
            cv2.putText(frame, last_display_text, (10, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        elif posture_status == "Good":
            cv2.putText(frame, last_display_text, (10, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        else:
            cv2.putText(frame, last_display_text, (10, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Distance: {last_distance_status}", (10, 80),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        cv2.putText(frame, last_fps_text, (w-120, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        if last_distance_status == "TOO CLOSE":
            cv2.putText(frame, "Move back from screen!", (w//2-140, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        elif last_distance_status == "Too far":
            cv2.putText(frame, "Move closer to screen", (w//2-130, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        stats.update({
            'posture_status': posture_status,
            'neck_angle': f"{smoothed:.1f}",
            'distance_status': distance_status,
            'fps': f"{fps:.1f}"
        })

        with lock:
            outputFrame = frame

def generate():
    global outputFrame, lock
    while True:
        with lock:
            if outputFrame is None:
                time.sleep(0.01)
                continue
            frame = outputFrame
        
        (flag, encodedImage) = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 55])
        if not flag:
            continue
        
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' +
               bytearray(encodedImage) + b'\r\n')

@app.route("/video_feed")
def video_feed():
    return Response(generate(),
                    mimetype="multipart/x-mixed-replace; boundary=frame")

@app.route("/stats")
def get_stats():
    return jsonify(stats)

@app.route("/")
def index():
    return """
    <html>
      <head>
        <title>Posture Monitor</title>
        <style>
          body {
            background-color: #1a1a1a;
            color: #ffffff;
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
          }
          .container {
            max-width: 1200px;
            margin: 0 auto;
          }
          h1 {
            text-align: center;
            color: #00ff88;
            margin-bottom: 30px;
          }
          .content {
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
          }
          .video-container {
            flex: 1;
            min-width: 640px;
          }
          .video-container img {
            width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 4px 20px rgba(0,255,136,0.3);
          }
          .stats-panel {
            flex: 0 0 300px;
            background: #2a2a2a;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.5);
          }
          .stat-item {
            padding: 15px;
            margin: 10px 0;
            background: #333;
            border-radius: 5px;
            border-left: 4px solid #00ff88;
          }
          .stat-label {
            font-size: 14px;
            color: #aaa;
            margin-bottom: 5px;
          }
          .stat-value {
            font-size: 24px;
            font-weight: bold;
            color: #00ff88;
          }
          .info {
            margin-top: 20px;
            padding: 15px;
            background: #2a2a2a;
            border-radius: 5px;
            font-size: 14px;
            color: #aaa;
          }
          .good { color: #00ff88 !important; }
          .bad { color: #ff4444 !important; }
          .warning { color: #ff8800 !important; }
        </style>
        <script>
          function updateStats() {
            fetch('/stats')
              .then(r => r.json())
              .then(data => {
                document.getElementById('posture').textContent = data.posture_status;
                document.getElementById('angle').textContent = data.neck_angle + '°';
                document.getElementById('distance').textContent = data.distance_status;
                document.getElementById('fps').textContent = data.fps;
                
                const postureEl = document.getElementById('posture');
                postureEl.className = 'stat-value ' + (data.posture_status === 'Good' ? 'good' : 'bad');
                
                const distanceEl = document.getElementById('distance');
                distanceEl.className = 'stat-value ' + (data.distance_status === 'OK' ? 'good' : 'warning');
              });
          }
          setInterval(updateStats, 1000);
          window.onload = updateStats;
        </script>
      </head>
      <body>
        <div class="container">
          <h1>Trợ Lý Tư Thế Ngồi</h1>
          <div class="content">
            <div class="video-container">
              <img src="/video_feed" />
            </div>
            <div class="stats-panel">
              <h2 style="margin-top:0; color:#00ff88;">Thống Kê</h2>
              <div class="stat-item">
                <div class="stat-label">Tư Thế</div>
                <div class="stat-value" id="posture">-</div>
              </div>
              <div class="stat-item">
                <div class="stat-label">Góc Cổ</div>
                <div class="stat-value" id="angle">-</div>
              </div>
              <div class="stat-item">
                <div class="stat-label">Khoảng Cách</div>
                <div class="stat-value" id="distance">-</div>
              </div>
              <div class="stat-item">
                <div class="stat-label">FPS</div>
                <div class="stat-value" id="fps">-</div>
              </div>
              <div class="info">
                <strong>Hướng Dẫn:</strong><br>
                • Tốt: góc cổ dưới 35°<br>
                • Giữ lưng thẳng<br>
                • Đầu thẳng hàng với cột sống<br>
                • Giữ khoảng cách phù hợp<br>
                • Cảnh báo bằng giọng nói tiếng Việt<br>
                • Nghỉ ngơi mỗi 20 phút
              </div>
            </div>
          </div>
        </div>
      </body>
    </html>
    """

if __name__ == '__main__':
    print("Khởi động Trợ Lý Tư Thế với Giọng Nói Tiếng Việt...")
    print("Truy cập tại: http://localhost:5000")
    
    t = threading.Thread(target=detect_posture)
    t.daemon = True
    t.start()
    
    app.run(host="0.0.0.0", port=5000, debug=False, threaded=True, use_reloader=False)
